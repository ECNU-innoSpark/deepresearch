# Deep Research System

åŸºäº LangGraph çš„å¤šæ™ºèƒ½ä½“æ·±åº¦ç ”ç©¶ç³»ç»Ÿï¼Œé‡‡ç”¨ "Roma" æ¨¡å¼å®ç°è‡ªåŠ¨åŒ–ç ”ç©¶æµæ°´çº¿ã€‚

## ç‰¹æ€§

- ğŸ”„ **å¤šæ™ºèƒ½ä½“ååŒ**: ä»»åŠ¡æ‹†è§£ã€è§„åˆ’ã€æ‰§è¡Œã€ç­›é€‰ã€å†™ä½œã€å®¡æŸ¥å…­å¤§Agent
- ğŸ”— **LangGraphç¼–æ’**: åŸºäºçŠ¶æ€å›¾çš„å·¥ä½œæµç®¡ç†ï¼Œæ”¯æŒæ¡ä»¶è·¯ç”±å’Œå¾ªç¯
- ğŸ“š **å¤šæ•°æ®æºé›†æˆ**: Webæœç´¢(Tavily/Google/Bing) + RAGFlowçŸ¥è¯†åº“ + MCPåè®®
- ğŸ“ **å­¦æœ¯çº§å¼•ç”¨**: è‡ªåŠ¨å¼•ç”¨ç®¡ç†ï¼Œç”Ÿæˆè§„èŒƒçš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨
- âš™ï¸ **é«˜åº¦å¯é…ç½®**: YAMLé…ç½®æ–‡ä»¶ï¼Œæ”¯æŒç¯å¢ƒå˜é‡ï¼Œæ¯ä¸ªAgentå¯ç‹¬ç«‹é…ç½®LLM
- ğŸ§ª **Mockæ¨¡å¼**: å®Œæ•´çš„Mockå®ç°ï¼Œä¾¿äºæµ‹è¯•å’Œæ¼”ç¤º

## å·¥ä½œæµç¨‹

```mermaid
graph TD
    A[Start] --> B[Decompose ä»»åŠ¡æ‹†è§£]
    B --> C[Plan è§„åˆ’]
    C --> D[Execute æ‰§è¡Œ]
    D --> E{å…¨éƒ¨å®Œæˆ?}
    E -->|å¦| D
    E -->|æ˜¯| F[Select ç­›é€‰]
    F --> G[Write å†™ä½œ]
    G --> H[Review å®¡æŸ¥]
    H --> I{é€šè¿‡?}
    I -->|éœ€è¦æ›´å¤šæ•°æ®| C
    I -->|éœ€è¦é‡å†™| G
    I -->|æ˜¯| J[End]
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd deep_research
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶ç¤ºä¾‹é…ç½®
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„APIå¯†é’¥
```

### 3. è¿è¡Œæ¼”ç¤º

```bash
# ä½¿ç”¨Mockæ¨¡å¼æ¼”ç¤ºï¼ˆæ— éœ€APIå¯†é’¥ï¼‰
python demo.py

# æŸ¥çœ‹å·¥ä½œæµç¨‹å›¾
python main.py --visualize
```

### 4. è¿è¡ŒçœŸå®ç ”ç©¶

```bash
# åŸºç¡€ç”¨æ³•
python main.py "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨"

# æŒ‡å®šè¾“å‡ºç›®å½•å’Œè¯¦ç»†æ¨¡å¼
python main.py "é‡å­è®¡ç®—çš„å‘å±•ç°çŠ¶" -o ./output -v

# ä½¿ç”¨Mockå·¥å…·æµ‹è¯•
python main.py "æµ‹è¯•é—®é¢˜" --mock
```

### 5. æŸ¥çœ‹è¿è¡Œè¿›åº¦ä¸ä¸­é—´ç»“æœ

è¿è¡Œåˆ°å“ªä¸€æ­¥ã€æ¯æ­¥çš„ä¸­é—´ç»“æœå¯ä»¥è¿™æ ·æŸ¥çœ‹ï¼š

```bash
# æ¯æ­¥å®Œæˆååœ¨æ§åˆ¶å°æ‰“å°å½“å‰çŠ¶æ€æ‘˜è¦ï¼ˆå­ä»»åŠ¡ã€æ•°æ®æ¡æ•°ã€è‰ç¨¿é¢„è§ˆã€å®¡æŸ¥ç»“æœç­‰ï¼‰
python main.py "ä½ çš„ç ”ç©¶é—®é¢˜" --show-state

# åŒæ—¶æ˜¾ç¤ºæœ¬æ­¥æ›´æ–°çš„å­—æ®µï¼ˆworkflow_statusã€å­ä»»åŠ¡æ•°ã€åŸå§‹æ•°æ®æ¡æ•°ç­‰ï¼‰
python main.py "ä½ çš„ç ”ç©¶é—®é¢˜" -v --show-state

# æ¯æ­¥å®ŒæˆåæŠŠä¸­é—´çŠ¶æ€ä¿å­˜ä¸º JSON åˆ°è¾“å‡ºç›®å½•ï¼ˆæˆ– ./intermediateï¼‰
python main.py "ä½ çš„ç ”ç©¶é—®é¢˜" -o ./output --save-intermediate
```

**çŠ¶æ€æ‘˜è¦åŒ…å«ï¼š**
- å­ä»»åŠ¡åˆ—è¡¨ï¼ˆIDã€é—®é¢˜æ‘˜è¦ï¼‰
- æ‰§è¡Œè®¡åˆ’ï¼ˆtask_planï¼‰
- å½“å‰æ‰§è¡Œåˆ°ç¬¬å‡ ä¸ªä»»åŠ¡ï¼ˆcurrent_task_indexï¼‰
- åŸå§‹æ•°æ®æ¡æ•°ï¼ˆæŒ‰æœç´¢/RAG åˆ†ç±»ï¼‰
- ç­›é€‰åæ•°æ®æ¡æ•°
- æŠ¥å‘Šè‰ç¨¿å­—æ•°ä¸é¢„è§ˆ
- å®¡æŸ¥ç»“æœï¼ˆé€šè¿‡/è·¯ç”±ã€é—®é¢˜åˆ—è¡¨ï¼‰
- é”™è¯¯åˆ—è¡¨ï¼ˆå¦‚æœ‰ï¼‰

**ä¿å­˜çš„ä¸­é—´çŠ¶æ€ JSONï¼š** æ¯æ­¥ä¸€ä¸ªæ–‡ä»¶ï¼Œå¦‚ `state_step_01_decompose.json`ã€`state_step_02_plan.json`ï¼Œä¾¿äºäº‹ååˆ†ææˆ–è°ƒè¯•ã€‚

## é…ç½®è¯´æ˜

### å¤šLLM APIé…ç½® (config/settings.yaml)

**æ¯ä¸ªAgentå¯ä»¥ä½¿ç”¨å®Œå…¨ä¸åŒçš„LLM API**ï¼ŒåŒ…æ‹¬ä¸åŒçš„æä¾›å•†ã€æ¨¡å‹å’Œå‚æ•°ï¼š

```yaml
llm:
  # é»˜è®¤é…ç½®
  default:
    base_url: "https://api.openai.com/v1"
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4o"
  
  # æ¯ä¸ªAgentç‹¬ç«‹é…ç½®
  agents:
    # ä»»åŠ¡æ‹†è§£ - ä½¿ç”¨DeepSeek (ä¾¿å®œ)
    decompose:
      base_url: "https://api.deepseek.com/v1"
      api_key: "${DEEPSEEK_API_KEY}"
      model: "deepseek-chat"
      temperature: 0.5
    
    # æ‰§è¡Œ - ä½¿ç”¨æœ¬åœ°Ollama (å…è´¹)
    execution:
      base_url: "http://localhost:11434/v1"
      api_key: "ollama"
      model: "qwen2.5:14b"
    
    # å†™ä½œ - ä½¿ç”¨GPT-4o (é«˜è´¨é‡)
    writing:
      base_url: "https://api.openai.com/v1"
      api_key: "${OPENAI_API_KEY}"
      model: "gpt-4o"
      max_tokens: 8192
```

**æ”¯æŒçš„APIæä¾›å•†**ï¼š
| æä¾›å•† | base_url | ç¯å¢ƒå˜é‡ |
|--------|----------|----------|
| OpenAI | `https://api.openai.com/v1` | `OPENAI_API_KEY` |
| DeepSeek | `https://api.deepseek.com/v1` | `DEEPSEEK_API_KEY` |
| Qwen | `https://dashscope.aliyuncs.com/compatible-mode/v1` | `QWEN_API_KEY` |
| æ™ºè°±GLM | `https://open.bigmodel.cn/api/paas/v4` | `ZHIPU_API_KEY` |
| Moonshot | `https://api.moonshot.cn/v1` | `MOONSHOT_API_KEY` |
| Ollama | `http://localhost:11434/v1` | ä¸éœ€è¦ |
| OneAPI | `http://localhost:3000/v1` | `ONEAPI_API_KEY` |

> å‚è€ƒ `config/settings.example.yaml` è·å–å®Œæ•´çš„å¤šLLMé…ç½®ç¤ºä¾‹

### å·¥å…·é…ç½® (config/tools_config.yaml)

```yaml
search:
  provider: "tavily"  # tavily, google, bing
  tavily:
    api_key: "${TAVILY_API_KEY}"

ragflow:
  enabled: true
  base_url: "http://localhost:9380"
  api_key: "${RAGFLOW_API_KEY}"
```

## é¡¹ç›®ç»“æ„

```
deep_research/
â”œâ”€â”€ config/           # é…ç½®æ–‡ä»¶
â”œâ”€â”€ core/             # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ state.py      # çŠ¶æ€å®šä¹‰
â”‚   â”œâ”€â”€ llm_client.py # LLMå®¢æˆ·ç«¯
â”‚   â””â”€â”€ citation_manager.py  # å¼•ç”¨ç®¡ç†
â”œâ”€â”€ agents/           # Agentå®ç°
â”‚   â”œâ”€â”€ prompts/      # Promptæ¨¡æ¿
â”‚   â”œâ”€â”€ decompose.py  # ä»»åŠ¡æ‹†è§£
â”‚   â”œâ”€â”€ plan.py       # è§„åˆ’
â”‚   â”œâ”€â”€ execution.py  # æ‰§è¡Œ
â”‚   â”œâ”€â”€ selection.py  # ç­›é€‰
â”‚   â”œâ”€â”€ writing.py    # å†™ä½œ
â”‚   â””â”€â”€ review.py     # å®¡æŸ¥
â”œâ”€â”€ tools/            # å·¥å…·å°è£…
â”‚   â”œâ”€â”€ search_provider.py   # æœç´¢
â”‚   â”œâ”€â”€ ragflow_provider.py  # RAGFlow
â”‚   â””â”€â”€ mcp_client.py        # MCP
â”œâ”€â”€ workflow.py       # å·¥ä½œæµå®šä¹‰
â”œâ”€â”€ main.py           # å…¥å£
â””â”€â”€ demo.py           # æ¼”ç¤ºè„šæœ¬
```

## æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_basic.py -v
pytest tests/test_workflow_mock.py -v
```

## æ‰©å±•æŒ‡å—

### æ·»åŠ æ–°çš„æœç´¢æä¾›å•†

1. åœ¨ `tools/search_provider.py` ä¸­åˆ›å»ºæ–°çš„Providerç±»
2. ç»§æ‰¿ `BaseSearchProvider` å¹¶å®ç° `search` æ–¹æ³•
3. åœ¨ `SearchProvider` å·¥å‚ç±»ä¸­æ³¨å†Œ

### æ·»åŠ æ–°çš„Agent

1. åœ¨ `agents/prompts/` ä¸­åˆ›å»ºpromptæ–‡ä»¶
2. åœ¨ `agents/` ä¸­åˆ›å»ºagentå®ç°
3. åœ¨ `workflow.py` ä¸­æ·»åŠ èŠ‚ç‚¹å’Œè¾¹

### è‡ªå®šä¹‰å·¥ä½œæµ

```python
from workflow import create_workflow

# åˆ›å»ºè‡ªå®šä¹‰å·¥ä½œæµ
workflow = create_workflow()

# æ·»åŠ æ–°èŠ‚ç‚¹
workflow.add_node("my_node", my_node_function)

# ç¼–è¯‘
compiled = workflow.compile()
```

## è®¸å¯è¯

MIT License
